По метрике precision:
Мы можем увидеть, что ансамблевые модели отработали лучше всего, причем до подбора гипепараметров. После подбора лучше всего сработали опять же ансмблевые модели. Из неансамблевых лучше всего сработала машина опорных векторов, а хуже всего - метод ближайших соседей с подобранными гиперпараметрами.

По метрике recall:
Мы видим, что лучше всего сработала машина опорных векторов и логистическая регрессия. Анасамблевые модели же сработали хуже остальных.

По f1:
Снова видим превосходство ансамблевых моделей, и снова видим, что хуже всего сработал метод ближайших соседей.

По roc-кривой:
Опять же видим, что бустинг и случайный лес работает лучше, чем неансамблевые модели, а линейная модель окахалась хуже всего.

Если смотреть по кривой обучения и кросс-валидации, то заметим, что большниство моделей после подбора гиперпараметров отработали хуже baseline. Улучшился заметно градиентый бустинг, поэтому можно сказать, что обобщая все метрики, на данном наборе данных метод градиентного бустинга работает лучше всего. Далее можно поставить случайный лес. Из оставшихся менее всего потерял метод логистической регрессииЮ а более плохо сработал метод ближайших соседей.
